{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhrjpLgS_yAB"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "# Included the 'SPECIAL_CONSIDERATIONSS' in the dropped collumns in an attempt to optimize the model.\n",
        "#Special considerations is not a specific enough feature to dramatically effect the model so we will drop it in an attempt to increase the weighting of more practical business features.\n",
        "application_df = application_df.drop(columns= ['EIN', 'NAME'])"
      ],
      "metadata": {
        "id": "hmEn0jBlCVd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS3ERj0wCca4",
        "outputId": "489d08bf-3daa-4186-bf67-76d6f4a689e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AeAvZnvCf3D",
        "outputId": "b7de23aa-cd24-4008-e321-315e4faf77c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "# For this excercise my value count cut-off was 25\n",
        "application_to_replace = []\n",
        "app_value_count = application_df['APPLICATION_TYPE'].value_counts().reset_index()\n",
        "replace_app = app_value_count[app_value_count['APPLICATION_TYPE'] < 25]\n",
        "\n",
        "application_to_replace_to_replace = replace_app['index'].tolist()\n",
        "# Replace in dataframe\n",
        "for app in application_to_replace:\n",
        "  application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n"
      ],
      "metadata": {
        "id": "vrxQ_tXXCf5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "#  Cut-Off: 110\n",
        "classifications_to_replace = []\n",
        "class_value_counts_2 = application_df['CLASSIFICATION'].value_counts().reset_index()\n",
        "replace_class = class_value_counts_2[class_value_counts_2['CLASSIFICATION'] <= 60]\n",
        "\n",
        "classifications_to_replace = replace_class['index'].tolist()\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "  application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlifADxdCf8O",
        "outputId": "dfcbc550-47c7-400a-edf8-e3ae93c8d063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "Other      499\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "application_df_dummies = pd.get_dummies(application_df, columns= ['INCOME_AMT', 'CLASSIFICATION', 'APPLICATION_TYPE',  'ORGANIZATION', 'AFFILIATION', \"USE_CASE\", 'SPECIAL_CONSIDERATIONS'])"
      ],
      "metadata": {
        "id": "Gbfc_MwcCf_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "features_df = application_df_dummies.drop(columns=['IS_SUCCESSFUL'])\n",
        "target_df = application_df_dummies['IS_SUCCESSFUL']\n",
        "X = features_df.values\n",
        "y = target_df.values\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "ilCuSWMRCgB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "YUeG5I8lCgEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn_model.add(tf.keras.layers.Dense(units=59, activation=\"relu\", input_dim=59))\n",
        "\n",
        "\n",
        "# Second hidden layer\n",
        "nn_model.add(tf.keras.layers.Dense(units=59, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "#Added an additional hidden layer to increase the number of nodes in the model and attempt to increase model fit.\n",
        "#This addition does not overly crowd the hyperparameters as it sticks to best practice of 2-4 hidden layers but attempts to increase the models learning.\n",
        "nn_model.add(tf.keras.layers.Dense(units=59, activation=\"elu\"))\n",
        "nn_model.add(tf.keras.layers.Dense(units=59, activation=\"elu\"))\n",
        "# Output layer\n",
        "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B67eu5y3CgHd",
        "outputId": "e1fcac39-d39a-40d7-a96a-8566530c96cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_59 (Dense)            (None, 59)                3540      \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 59)                3540      \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 59)                3540      \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 59)                3540      \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 1)                 60        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,220\n",
            "Trainable params: 14,220\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "CFT_UACZCgKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "#Reduced number of Epochs to 50 from 100 as previous model seemed to reach marginal utility of training around 50 epochs\n",
        "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2-fU3yjDcuY",
        "outputId": "6fe0a840-3b58-4692-dbd9-f428e88b08e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "804/804 [==============================] - 4s 3ms/step - loss: 0.5702 - accuracy: 0.7214\n",
            "Epoch 2/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5553 - accuracy: 0.7292\n",
            "Epoch 3/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7315\n",
            "Epoch 4/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5496 - accuracy: 0.7306\n",
            "Epoch 5/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5467 - accuracy: 0.7313\n",
            "Epoch 6/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5462 - accuracy: 0.7328\n",
            "Epoch 7/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5453 - accuracy: 0.7333\n",
            "Epoch 8/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7327\n",
            "Epoch 9/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7332\n",
            "Epoch 10/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7348\n",
            "Epoch 11/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7349\n",
            "Epoch 12/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7365\n",
            "Epoch 13/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5413 - accuracy: 0.7353\n",
            "Epoch 14/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7352\n",
            "Epoch 15/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.7358\n",
            "Epoch 16/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5395 - accuracy: 0.7364\n",
            "Epoch 17/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5389 - accuracy: 0.7372\n",
            "Epoch 18/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7378\n",
            "Epoch 19/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5382 - accuracy: 0.7382\n",
            "Epoch 20/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7381\n",
            "Epoch 21/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7372\n",
            "Epoch 22/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7376\n",
            "Epoch 23/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5367 - accuracy: 0.7390\n",
            "Epoch 24/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5357 - accuracy: 0.7387\n",
            "Epoch 25/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5363 - accuracy: 0.7386\n",
            "Epoch 26/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5355 - accuracy: 0.7393\n",
            "Epoch 27/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5355 - accuracy: 0.7393\n",
            "Epoch 28/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7390\n",
            "Epoch 29/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7399\n",
            "Epoch 30/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5346 - accuracy: 0.7385\n",
            "Epoch 31/50\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5347 - accuracy: 0.7390\n",
            "Epoch 32/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5336 - accuracy: 0.7402\n",
            "Epoch 33/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7401\n",
            "Epoch 34/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5340 - accuracy: 0.7402\n",
            "Epoch 35/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5337 - accuracy: 0.7401\n",
            "Epoch 36/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5339 - accuracy: 0.7400\n",
            "Epoch 37/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5329 - accuracy: 0.7407\n",
            "Epoch 38/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7404\n",
            "Epoch 39/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7402\n",
            "Epoch 40/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7400\n",
            "Epoch 41/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7409\n",
            "Epoch 42/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5324 - accuracy: 0.7413\n",
            "Epoch 43/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5323 - accuracy: 0.7410\n",
            "Epoch 44/50\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5319 - accuracy: 0.7404\n",
            "Epoch 45/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7409\n",
            "Epoch 46/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7414\n",
            "Epoch 47/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7410\n",
            "Epoch 48/50\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5315 - accuracy: 0.7412\n",
            "Epoch 49/50\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7396\n",
            "Epoch 50/50\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5313 - accuracy: 0.7399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN0HxkzYDcxM",
        "outputId": "424014d6-b2bb-4f18-8649-2bf54d02af6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.5591 - accuracy: 0.7304 - 509ms/epoch - 2ms/step\n",
            "Loss: 0.5591038465499878, Accuracy: 0.7303789854049683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.saving.saving_api import load_model\n",
        "# Export our model to HDF5 file\n",
        "nn_model.save('AlphabetSoupCharity_Optimization.h5', save_format= 'h5')\n",
        "nn_model = load_model('AlphabetSoupCharity_Optimization.h5')"
      ],
      "metadata": {
        "id": "dbejo8dHCgNA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}